{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Populations connected directly"
   ]
  },
  {
   "metadata": {},
   "source": [
    "# Populations connected directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn"
      "Requirement already satisfied: matplotlib>=2.1.2 in /usr/lib/python3/dist-packages (from seaborn) (3.0.2)\r\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pylab\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import nest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "exc_cfg = {\"I_e\": 200.0, \"tau_m\": 20.0}\n",
    "nest.CopyModel(\"iaf_psc_alpha\", \"exc_iaf_psc_alpha\")\n",
    "nest.SetDefaults(\"exc_iaf_psc_alpha\", exc_cfg)\n",
    "\n",
    "inh_cfg = {\"I_e\": 200.}\n",
    "\n",
    "inner_connectivity = .1\n",
    "outer_connectivity = .0025\n",
    "pop_size = 4175\n",
    "inh_part = .2\n",
    "\n",
    "# simulation times\n",
    "t_sim = 1500.\n",
    "\n",
    "# spike detectors and multimeters\n",
    "n_devices = 100\n",
    "\n",
    "# poisson generators per neuron\n",
    "# NOTE: much more than 20 are not possible with 16 GB RAM\n",
    "n_pg = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and connect neurons and devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each population is composed of 4,175 IAF neurons from which\n",
    "80% are excitatory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each neuron receives a synapse from 10% of randomly selected cells inside its population.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = nest.Create(\"exc_iaf_psc_alpha\", pop_size)\n",
    "p2 = nest.Create(\"exc_iaf_psc_alpha\", pop_size)\n",
    "p3 = nest.Create(\"exc_iaf_psc_alpha\", pop_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make 20% of the neurons inhibitory\n",
    "inh_boundary = int(pop_size * .2)\n",
    "for p in [p1,p2,p3]:\n",
    "    for neuron in p[:inh_boundary]:\n",
    "        nest.SetStatus(neuron, inh_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomize inital membrane voltage\n",
    "V_range = np.linspace(-77,-55,100)\n",
    "\n",
    "nest.SetStatus(p1, {\"V_m\": np.random.choice(V_range)})    \n",
    "nest.SetStatus(p2, {\"V_m\": np.random.choice(V_range)})\n",
    "nest.SetStatus(p3, {\"V_m\": np.random.choice(V_range)})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index options\n",
    "opt = np.arange(0, pop_size)\n",
    "# number of intrapopulational connections\n",
    "num_inner_conn = int(pop_size * inner_connectivity)\n",
    "# index border of the inhibitory part\n",
    "inh_border = int(pop_size * inh_part)\n",
    "\n",
    "# for each neuron randomize a percentage of the other neurons to be connected to\n",
    "for i, (n1,n2,n3) in enumerate(zip(p1,p2,p3)):\n",
    "    \n",
    "    c1 = np.random.choice(opt, num_inner_conn, replace=False)\n",
    "    c2 = np.random.choice(opt, num_inner_conn, replace=False)\n",
    "    c3 = np.random.choice(opt, num_inner_conn, replace=False)\n",
    "    \n",
    "    # different weights for inhibitory and excitatory neurons\n",
    "    nest.Connect(p1[c1[c1 <inh_border]], n1, syn_spec =  {'weight' : -1} )    \n",
    "    nest.Connect(p1[c1[c1 >= inh_border]], n1)   \n",
    "    \n",
    "    nest.Connect(p2[c2[c2 < inh_border]], n2, syn_spec =  {'weight' : -1} )    \n",
    "    nest.Connect(p2[c2[c2 >= inh_border]], n2)       \n",
    "    \n",
    "    nest.Connect(p3[c3[c3 < inh_border]], n3, syn_spec =  {'weight' : -1} )    \n",
    "    nest.Connect(p3[c3[c3 >= inh_border]], n3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_cfg = {\"rate\": 5.}\n",
    "for i, (n1, n2, n3) in enumerate(zip(p1, p2, p3)):\n",
    "    pg1 = nest.Create(\"poisson_generator\", n_pg, pg_cfg)\n",
    "    nest.Connect(pg1, n1)\n",
    "    \n",
    "    pg2 = nest.Create(\"poisson_generator\", n_pg, pg_cfg)\n",
    "    nest.Connect(pg2, n2)\n",
    "    \n",
    "    pg3 = nest.Create(\"poisson_generator\", n_pg, pg_cfg)\n",
    "    nest.Connect(pg3, n3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multimeters ans spike detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = [nest.Create(\"multimeter\", params={\"time_in_steps\":True, \"record_from\":[\"V_m\"]}) for _ in range(300)]\n",
    "s = [nest.Create(\"spike_detector\") for _ in range(300)]\n",
    "opt_inh = np.arange(0, 835)\n",
    "opt_exc = np.arange(835, 4175)\n",
    "num_inh = int(np.around(n_devices * inh_part))\n",
    "num_exc = int(np.around(n_devices * (1. - inh_part)))\n",
    "\n",
    "n1_inh = np.random.choice(opt_inh, num_inh, replace=False)\n",
    "n2_inh = np.random.choice(opt_inh, num_inh, replace=False)\n",
    "n3_inh = np.random.choice(opt_inh, num_inh, replace=False)\n",
    "\n",
    "n1_exc = np.random.choice(opt_exc, num_exc, replace=False)\n",
    "n2_exc = np.random.choice(opt_exc, num_exc, replace=False)\n",
    "n3_exc = np.random.choice(opt_exc, num_exc, replace=False)\n",
    "\n",
    "# multimeter and spike detector connections\n",
    "for i in range(num_inh):\n",
    "    # inhibitory\n",
    "    nest.Connect(m[n_devices - 1 - i],p1[n1_inh[i]])\n",
    "    nest.Connect(p1[n1_inh[i]], s[n_devices - 1 - i])\n",
    "    nest.Connect(m[2 * n_devices - 1 - i],p2[n2_inh[i]])\n",
    "    nest.Connect(p2[n2_inh[i]], s[2 * n_devices - 1 - i])\n",
    "    nest.Connect(m[3 * n_devices - 1 - i],p3[n3_inh[i]])\n",
    "    nest.Connect(p3[n3_inh[i]], s[3 * n_devices - 1 - i])\n",
    "    \n",
    "    \n",
    "for i in range(num_exc):\n",
    "    # excitatory\n",
    "    nest.Connect(m[i],p1[n1_exc[i]])\n",
    "    nest.Connect(p1[n1_exc[i]], s[i])\n",
    "    nest.Connect(m[i + n_devices],p2[n2_exc[i]])\n",
    "    nest.Connect(p2[n2_exc[i]], s[i + n_devices])\n",
    "    nest.Connect(m[i + 2 * n_devices],p3[n3_exc[i]])\n",
    "    nest.Connect(p3[n3_exc[i]], s[i + 2 * n_devices])\n",
    "\n",
    "    \n",
    "# interpopulational connections    \n",
    "opt = np.arange(inh_boundary, pop_size)\n",
    "num_outer_conn = int(pop_size * outer_connectivity)\n",
    "for n1,n2 in zip(p1, p2):\n",
    "    c12 = np.random.choice(opt, num_outer_conn, replace=False)\n",
    "    c21 = np.random.choice(opt, num_outer_conn, replace=False)\n",
    "     \n",
    "    nest.Connect(p1[c12], n2, syn_spec = {'delay': np.random.choice(np.linspace(2,20,100))} ) \n",
    "    nest.Connect(p2[c21], n1, syn_spec = {'delay': np.random.choice(np.linspace(2,20,100))} )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "metadata": {},
   "source": [
    "## Simulation and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raster_plot():\n",
    "    \n",
    "    num_inh = np.around(n_devices * inh_part)\n",
    "    num_exc = np.around(n_devices * (1 - inh_part))\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "\n",
    "    pylab.figure()\n",
    "    for i, sd in enumerate(s):\n",
    "        dSD = nest.GetStatus(sd, keys=\"events\")[0]\n",
    "        ts = dSD[\"times\"]\n",
    "        if i % n_devices >= num_exc:\n",
    "            pylab.plot(ts, [i]*len(ts), \".\", color=\"gray\", markersize=2)\n",
    "        else:\n",
    "            pylab.plot(ts, [i]*len(ts), \".\", color=\"black\", markersize=2)\n",
    "\n",
    "\n",
    "    plt.axhspan(0,num_exc,facecolor=\"lightblue\",alpha=0.2)\n",
    "    plt.axhspan(num_exc,n_devices,facecolor=\"lightblue\",alpha=0.1)\n",
    "    plt.axhspan(n_devices,n_devices + num_exc,facecolor=\"lightgreen\",alpha=0.2)\n",
    "    plt.axhspan(n_devices + num_exc,2 * n_devices,facecolor=\"lightgreen\",alpha=0.1)\n",
    "    plt.axhspan(2 * n_devices,2 * n_devices + num_exc,facecolor=\"blue\",alpha=0.2)\n",
    "    plt.axhspan(2 * n_devices + num_exc,3 * n_devices,facecolor=\"blue\",alpha=0.1)\n",
    "    pylab.title(\"Raster plot\")\n",
    "    pylab.xlabel(\"time in ms\")\n",
    "    pylab.ylabel(\"neuron ID\")\n",
    "    pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,5)\n",
    "\n",
    "def plot_V(pops=[]):\n",
    "    \n",
    "    for idx, multimeter in enumerate(pops):\n",
    "\n",
    "        dmm = nest.GetStatus(multimeter)[0]\n",
    "        Vms = dmm[\"events\"][\"V_m\"]\n",
    "        ts = dmm[\"events\"][\"times\"]\n",
    "        plt.plot(ts, Vms)\n",
    "    \n",
    "    pylab.title(\"Merged V_ms\")\n",
    "    pylab.legend([\"alhpa\", \"beta\", \"gamma\"])\n",
    "    pylab.xlabel(\"t\")\n",
    "    pylab.ylabel(\"V_m\")\n",
    "    pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import KDTree\n",
    "\n",
    "def plot_spikes():\n",
    "    i1 = np.random.randint(n_devices)\n",
    "    i2 = np.random.randint(n_devices, 2 * n_devices)\n",
    "    i3 = np.random.randint(2 * n_devices, 3 * n_devices)\n",
    "    \n",
    "    sd1 = s[i1]\n",
    "    sd2 = s[i2]\n",
    "    sd3 = s[i3]\n",
    "    \n",
    "    ts1 = nest.GetStatus(sd1, keys=\"events\")[0][\"times\"]\n",
    "    ts2 = nest.GetStatus(sd2, keys=\"events\")[0][\"times\"]\n",
    "    ts3 = nest.GetStatus(sd3, keys=\"events\")[0][\"times\"]\n",
    "    \n",
    "    tree1 = KDTree(np.reshape(ts1, (len(ts1), 1)))\n",
    "    tree2 = KDTree(np.reshape(ts2, (len(ts2), 1)))\n",
    "    \n",
    "    nn_dist_12, _ = tree1.query(np.reshape(ts2, (len(ts2), 1)))\n",
    "    nn_dist_13, _ = tree1.query(np.reshape(ts3, (len(ts3), 1)))\n",
    "    nn_dist_23, _ = tree2.query(np.reshape(ts3, (len(ts3), 1)))\n",
    "    \n",
    "    pylab.figure()\n",
    "    \n",
    "    pylab.plot(ts2[1:], nn_dist_12[1:])\n",
    "    pylab.plot(ts3[1:], nn_dist_13[1:])\n",
    "    pylab.plot(ts3[1:], nn_dist_23[1:])\n",
    "    \n",
    "    pylab.plot(ts1, np.full((len(ts1)), 1), \".\")\n",
    "    pylab.plot(ts2, np.full((len(ts2)), 1), \".\")\n",
    "    pylab.plot(ts3, np.full((len(ts3)), 1), \".\")\n",
    "    \n",
    "    pylab.title(\"Spike distances between neurons\")\n",
    "    pylab.legend([\"alpha-beta\", \"alpha-gamma\", \"beta-gamma\"])\n",
    "    pylab.xlabel(\"t\")\n",
    "    pylab.ylabel(\"Distance\")\n",
    "    pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coinc_hists():\n",
    "    \n",
    "    # config\n",
    "    start_idx = 1500\n",
    "    end_idx = 1800\n",
    "    threshold = .001\n",
    "    n_samples = 300\n",
    "    \n",
    "    offsets = np.arange(-80, 80, 2)\n",
    "    hist12 = np.empty((n_samples, len(offsets)))\n",
    "    hist13 = np.empty((n_samples, len(offsets)))\n",
    "    hist23 = np.empty((n_samples, len(offsets)))\n",
    "    \n",
    "    for sample in range(n_samples):\n",
    "        \n",
    "    \n",
    "        idx1 = np.random.randint(n_devices)\n",
    "        idx2 = np.random.randint(n_devices, 2 * n_devices)\n",
    "        idx3 = np.random.randint(2 * n_devices, 3 * n_devices)\n",
    "\n",
    "        m1 = m[idx1]\n",
    "        m2 = m[idx2]\n",
    "        m3 = m[idx3]\n",
    "\n",
    "        Vms1 = nest.GetStatus(m1)[0][\"events\"][\"V_m\"]\n",
    "        Vms2 = nest.GetStatus(m2)[0][\"events\"][\"V_m\"]\n",
    "        Vms3 = nest.GetStatus(m3)[0][\"events\"][\"V_m\"]\n",
    "\n",
    "        for i, offset in enumerate(offsets):\n",
    "            diff12 = Vms1[start_idx : end_idx] - Vms2[start_idx + offset: end_idx + offset]\n",
    "            diff13 = Vms1[start_idx : end_idx] - Vms3[start_idx + offset: end_idx + offset]\n",
    "            diff23 = Vms2[start_idx : end_idx] - Vms3[start_idx + offset: end_idx + offset]\n",
    "            hist12[sample, i] = len(diff12[np.abs(diff12) < threshold])\n",
    "            hist13[sample, i] = len(diff13[np.abs(diff13) < threshold])\n",
    "            hist23[sample, i] = len(diff23[np.abs(diff23) < threshold])\n",
    "            \n",
    "    hist12_mean = np.mean(hist12, axis=0)\n",
    "    hist13_mean = np.mean(hist13, axis=0)\n",
    "    hist23_mean = np.mean(hist23, axis=0)\n",
    "    \n",
    "    max_y = np.max(hist12_mean) + 1\n",
    "        \n",
    "    pylab.figure()\n",
    "    pylab.title(\"alpha & beta\")\n",
    "    pylab.bar(offsets, hist12_mean)\n",
    "    pylab.ylim(0, max_y)\n",
    "    pylab.show()\n",
    "    pylab.figure()\n",
    "    pylab.title(\"alpha & gamma\")\n",
    "    pylab.bar(offsets, hist13_mean)\n",
    "    pylab.ylim(0, max_y)\n",
    "    pylab.show()\n",
    "    pylab.figure()\n",
    "    pylab.title(\"beta & gamma\")\n",
    "    pylab.bar(offsets, hist23_mean)\n",
    "    pylab.ylim(0, max_y)\n",
    "    pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def firing_hists():\n",
    "\n",
    "    # config\n",
    "    start_t = 0\n",
    "    end_t = 1500\n",
    "    bin_size = 1.\n",
    "    \n",
    "    ts1 = []      \n",
    "    ts2 = []      \n",
    "    ts3 = []    \n",
    "    \n",
    "    for i in range(n_devices):\n",
    "        ts1.append(nest.GetStatus(s[i], keys=\"events\")[0][\"times\"])\n",
    "        ts2.append(nest.GetStatus(s[i + n_devices], keys=\"events\")[0][\"times\"])\n",
    "        ts3.append(nest.GetStatus(s[i + 2 * n_devices], keys=\"events\")[0][\"times\"])\n",
    "        \n",
    "    ts1 = np.hstack(ts1)\n",
    "    ts2 = np.hstack(ts2)\n",
    "    ts3 = np.hstack(ts3)\n",
    "    \n",
    "    bins = np.arange(start_t, end_t, bin_size)\n",
    "    \n",
    "    hist1, _ = np.histogram(ts1, bins=bins)\n",
    "    hist2, _ = np.histogram(ts2, bins=bins)\n",
    "    hist3, _ = np.histogram(ts3, bins=bins)\n",
    "    \n",
    "    bin_means = (bins - bin_size / 2)[1:]\n",
    "    \n",
    "    pylab.figure()\n",
    "    pylab.plot(bin_means, hist1)\n",
    "    pylab.plot(bin_means, hist2)\n",
    "    pylab.plot(bin_means, hist3)\n",
    "    pylab.legend([\"alhpa\", \"beta\", \"gamma\"])\n",
    "    pylab.xlabel(\"t\")\n",
    "    pylab.ylabel(\"Number of spikes\")\n",
    "    pylab.title(\"PTSH\")\n",
    "    pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sns_plots():\n",
    "\n",
    "    # config\n",
    "    start_idx = 1000\n",
    "    \n",
    "    pal = sns.cubehelix_palette(3, rot=-.5, dark=.3)\n",
    "    \n",
    "    idx1 = np.random.randint(n_devices)\n",
    "    idx2 = np.random.randint(n_devices, 2 * n_devices)\n",
    "    idx3 = np.random.randint(2 * n_devices, 3 * n_devices)\n",
    "\n",
    "    m1 = m[idx1]\n",
    "    m2 = m[idx2]\n",
    "    m3 = m[idx3]\n",
    "\n",
    "    Vms1 = nest.GetStatus(m1)[0][\"events\"][\"V_m\"][start_idx:]\n",
    "    Vms2 = nest.GetStatus(m2)[0][\"events\"][\"V_m\"][start_idx:]\n",
    "    Vms3 = nest.GetStatus(m3)[0][\"events\"][\"V_m\"][start_idx:]\n",
    "\n",
    "    diff12 = Vms1 - Vms2\n",
    "    diff13 = Vms1 - Vms3\n",
    "    diff23 = Vms2 - Vms3\n",
    "    \n",
    "    data = [diff12, diff13, diff23]\n",
    "    sns.violinplot(data=data, palette=pal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest.Simulate(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest.Simulate(t_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firing_hists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coinc_hists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm3 = np.reshape([nest.GetStatus(mult)[0][\"events\"][\"V_m\"] for mult in m], (300,1999))\n",
    "\n",
    "with open(\"vm3.csv\",\"w+\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',')\n",
    "    csvWriter.writerows(vm3)\n",
    "\n",
    "with open(\"sd3.csv\",\"w+\") as my_csv:    \n",
    "    csvWriter = csv.writer(my_csv,delimiter=',')\n",
    "    for spiked in s:\n",
    "        csvWriter.writerow(nest.GetStatus(spiked)[0][\"events\"][\"times\"])"
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm3 = np.reshape([nest.GetStatus(mult)[0][\"events\"][\"V_m\"] for mult in m], (300,1999))\n",
    "\n",
    "with open(\"vm3.csv\",\"w+\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',')\n",
    "    csvWriter.writerows(vm3)\n",
    "\n",
    "with open(\"sd3.csv\",\"w+\") as my_csv:    \n",
    "    csvWriter = csv.writer(my_csv,delimiter=',')\n",
    "    for spiked in s:\n",
    "        csvWriter.writerow(nest.GetStatus(spiked)[0][\"events\"][\"times\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
