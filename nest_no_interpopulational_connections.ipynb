{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate populations of neurons using NEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /home/nest/.local/lib/python3.7/site-packages (0.10.1)\r\n",
      "Requirement already satisfied: matplotlib>=2.1.2 in /usr/lib/python3/dist-packages (from seaborn) (3.0.2)\r\n",
      "Requirement already satisfied: pandas>=0.22.0 in /usr/lib/python3/dist-packages (from seaborn) (0.23.3+dfsg)\r\n",
      "Requirement already satisfied: scipy>=1.0.1 in /usr/lib/python3/dist-packages (from seaborn) (1.2.2)\r\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/lib/python3/dist-packages (from seaborn) (1.16.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn\n",
    "import seaborn as sns\n",
    "from scipy.special import erf\n",
    "import pylab\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nest\n",
    "import csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create populations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each population is composed of 4,175 IAF neurons from which\n",
    "80% are excitatory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "exc_cfg = {\"I_e\": 200.0, \"tau_m\": 20.0}\n",
    "nest.CopyModel(\"iaf_psc_alpha\", \"exc_iaf_psc_alpha\")\n",
    "nest.SetDefaults(\"exc_iaf_psc_alpha\", exc_cfg)\n",
    "\n",
    "inh_cfg = {\"I_e\": 200.}\n",
    "\n",
    "inner_connectivity = .1\n",
    "outer_connectivity = .0025\n",
    "pop_size = 4175\n",
    "\n",
    "# simulation times\n",
    "t_sim = 1500.\n",
    "t_wu = 100.\n",
    "\n",
    "# spike detectors\n",
    "n_sds = 100\n",
    "\n",
    "# poisson generators per neuron\n",
    "# NOTE: much more than 20 are not possible with 16 GB RAM\n",
    "n_pg = 5\n",
    "\n",
    "# histograms of coincidences\n",
    "n_chists = 300\n",
    "\n",
    "# firing histogram\n",
    "n_fhist = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = nest.Create(\"exc_iaf_psc_alpha\", pop_size)\n",
    "p2 = nest.Create(\"exc_iaf_psc_alpha\", pop_size)\n",
    "p3 = nest.Create(\"exc_iaf_psc_alpha\", pop_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make 20% of the neurons inhibitory\n",
    "inh_boundary = int(pop_size * .2)\n",
    "for p in [p1,p2,p3]:\n",
    "    for neuron in p[:inh_boundary]:\n",
    "        nest.SetStatus(neuron, inh_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random start Vs for all neurons\n",
    "\"\"\"\n",
    "Vth=20.\n",
    "Vrest=10.\n",
    "V_range = Vrest + (Vth - Vrest)\n",
    "for n1,n2,n3 in zip(p1,p2,p3):\n",
    "    nest.SetStatus(n1, {\"V_m\": V_range * np.random.rand()})    \n",
    "    nest.SetStatus(n2, {\"V_m\": V_range * np.random.rand()})\n",
    "    nest.SetStatus(n3, {\"V_m\": V_range * np.random.rand()})    \n",
    "\"\"\"\n",
    "\n",
    "V_range = np.linspace(-77,-55,100)\n",
    "\n",
    "nest.SetStatus(p1, {\"V_m\": np.random.choice(V_range)})    \n",
    "nest.SetStatus(p2, {\"V_m\": np.random.choice(V_range)})\n",
    "nest.SetStatus(p3, {\"V_m\": np.random.choice(V_range)})    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First case: Connect neurons only within populations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each neuron receives a synapse from 10% of randomly selected cells inside its population.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = np.arange(0, pop_size)\n",
    "num_inner_conn = int(pop_size * inner_connectivity)\n",
    "for i, (n1,n2,n3) in enumerate(zip(p1,p2,p3)):\n",
    "    \n",
    "    # for each neuron randomize N * .1 ~ 417 neurons to connect to\n",
    "    c1 = np.random.choice(opt, num_inner_conn, replace=False)\n",
    "    c2 = np.random.choice(opt, num_inner_conn, replace=False)\n",
    "    c3 = np.random.choice(opt, num_inner_conn, replace=False)\n",
    "     \n",
    "    nest.Connect(p1[c1[c1 <835]], n1, syn_spec =  {'weight' : -1} )    \n",
    "    nest.Connect(p1[c1[c1 >= 835]], n1)   \n",
    "    \n",
    "    nest.Connect(p2[c2[c2 <835]], n2, syn_spec =  {'weight' : -1} )    \n",
    "    nest.Connect(p2[c2[c2 >= 835]], n2)       \n",
    "    \n",
    "    nest.Connect(p3[c3[c3 <835]], n3, syn_spec =  {'weight' : -1} )    \n",
    "    nest.Connect(p3[c3[c3 >= 835]], n3)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add external poisson noise\n",
    "pg_cfg = {\"rate\": 5.}\n",
    "for i, (n1, n2, n3) in enumerate(zip(p1, p2, p3)):\n",
    "    pg1 = nest.Create(\"poisson_generator\", n_pg, pg_cfg)\n",
    "    nest.Connect(pg1, n1)\n",
    "    \n",
    "    pg2 = nest.Create(\"poisson_generator\", n_pg, pg_cfg)\n",
    "    nest.Connect(pg2, n2)\n",
    "    \n",
    "    pg3 = nest.Create(\"poisson_generator\", n_pg, pg_cfg)\n",
    "    nest.Connect(pg3, n3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate, measure and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a multimeter and a spike detector for each population\n",
    "\"\"\"\n",
    "m1 = nest.Create(\"multimeter\")\n",
    "m2 = nest.Create(\"multimeter\")\n",
    "m3 = nest.Create(\"multimeter\")\n",
    "\n",
    "nest.SetStatus(m1, {\"time_in_steps\":True, \"record_from\":[\"V_m\"]})\n",
    "nest.SetStatus(m2, {\"time_in_steps\":True, \"record_from\":[\"V_m\"]})\n",
    "nest.SetStatus(m3, {\"time_in_steps\":True, \"record_from\":[\"V_m\"]})\n",
    "\"\"\"\n",
    "\n",
    "m = [nest.Create(\"multimeter\", params={\"time_in_steps\":True, \"record_from\":[\"V_m\"]}) for _ in range(300)]\n",
    "s = [nest.Create(\"spike_detector\") for _ in range(300)]\n",
    "opt_inh = np.arange(0, 835)\n",
    "opt_exc = np.arange(835, 4175)\n",
    "\n",
    "n1_inh = np.random.choice(opt_inh, 20, replace=False)\n",
    "n2_inh = np.random.choice(opt_inh, 20, replace=False)\n",
    "n3_inh = np.random.choice(opt_inh, 20, replace=False)\n",
    "\n",
    "n1_exc = np.random.choice(opt_exc, 80, replace=False)\n",
    "n2_exc = np.random.choice(opt_exc, 80, replace=False)\n",
    "n3_exc = np.random.choice(opt_exc, 80, replace=False)\n",
    "\n",
    "for i in range(20):\n",
    "    # inhibitory\n",
    "    nest.Connect(m[99-i],p1[n1_inh[i]])\n",
    "    nest.Connect(p1[n1_inh[i]], s[99-i])\n",
    "    nest.Connect(m[199-i],p2[n2_inh[i]])\n",
    "    nest.Connect(p2[n2_inh[i]], s[199-i])\n",
    "    nest.Connect(m[299-i],p3[n3_inh[i]])\n",
    "    nest.Connect(p3[n3_inh[i]], s[299-i])\n",
    "    \n",
    "    \n",
    "for i in range(80):\n",
    "    # excitatory\n",
    "    nest.Connect(m[i],p1[n1_exc[i]])\n",
    "    nest.Connect(p1[n1_exc[i]], s[i])\n",
    "    nest.Connect(m[i+100],p2[n2_exc[i]])\n",
    "    nest.Connect(p2[n2_exc[i]], s[i+100])\n",
    "    nest.Connect(m[i+200],p3[n3_exc[i]])\n",
    "    nest.Connect(p3[n3_exc[i]], s[i+200])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest.Simulate(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raster_plot():\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "\n",
    "    pylab.figure()\n",
    "    for i, sd in enumerate(s):\n",
    "        dSD = nest.GetStatus(sd, keys=\"events\")[0]\n",
    "        ts = dSD[\"times\"]\n",
    "        if i % 100 >= 80:\n",
    "            pylab.plot(ts, [i]*len(ts), \".\", color=\"gray\", markersize=2)\n",
    "        else:\n",
    "            pylab.plot(ts, [i]*len(ts), \".\", color=\"black\", markersize=2)\n",
    "\n",
    "\n",
    "    plt.axhspan(0,80,facecolor=\"lightblue\",alpha=0.2)\n",
    "    plt.axhspan(80,100,facecolor=\"lightblue\",alpha=0.1)\n",
    "    plt.axhspan(100,180,facecolor=\"lightgreen\",alpha=0.2)\n",
    "    plt.axhspan(180,200,facecolor=\"lightgreen\",alpha=0.1)\n",
    "    plt.axhspan(200,280,facecolor=\"blue\",alpha=0.2)\n",
    "    plt.axhspan(280,300,facecolor=\"blue\",alpha=0.1)\n",
    "    pylab.title(\"Raster plot\")\n",
    "    pylab.xlabel(\"time in ms\")\n",
    "    pylab.ylabel(\"neuron ID\")\n",
    "    pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,5)\n",
    "\n",
    "def plot_V(pops=[]):\n",
    "    \n",
    "    for idx, multimeter in enumerate(pops):\n",
    "\n",
    "        dmm = nest.GetStatus(multimeter)[0]\n",
    "        Vms = dmm[\"events\"][\"V_m\"]\n",
    "        ts = dmm[\"events\"][\"times\"]\n",
    "        plt.plot(ts, Vms)\n",
    "    \n",
    "    pylab.title(\"Merged V_ms\")\n",
    "    pylab.legend([\"alhpa\", \"beta\", \"gamma\"])\n",
    "    pylab.xlabel(\"t\")\n",
    "    pylab.ylabel(\"V_m\")\n",
    "    pylab.show()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import KDTree\n",
    "\n",
    "def plot_spikes(sds=[]):\n",
    "    pylab.figure()\n",
    "    for sd in sds:\n",
    "        dSD = nest.GetStatus(sd, keys=\"events\")[0]\n",
    "        ts = dSD[\"times\"]\n",
    "        my_tree = KDTree(np.reshape(ts, (len(ts), 1)))\n",
    "        for sd2 in sds:\n",
    "            if not np.array_equal(sd, sd2):\n",
    "                dSD2 = nest.GetStatus(sd2, keys=\"events\")[0]\n",
    "                ts2 = dSD2[\"times\"]\n",
    "                nn_dist, nn_idx = my_tree.query(np.reshape(ts2, (len(ts2), 1)))\n",
    "                pylab.plot(ts2[1:], nn_dist[1:])\n",
    "        pylab.plot(ts, np.full((len(ts)), 1), \".\")\n",
    "    \n",
    "    pylab.title(\"Spike distances between neurons\")\n",
    "    pylab.xlabel(\"t\")\n",
    "    pylab.ylabel(\"Distance\")\n",
    "    pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coinc_hists():\n",
    "    \n",
    "    start_idx = 100\n",
    "    end_idx = 400\n",
    "    threshold = .008\n",
    "    \n",
    "    offsets = np.arange(-80, 80, 2)\n",
    "    hist12 = np.empty((300, len(offsets)))\n",
    "    hist13 = np.empty((300, len(offsets)))\n",
    "    hist23 = np.empty((300, len(offsets)))\n",
    "    \n",
    "    for sample in range(300):\n",
    "        \n",
    "    \n",
    "        idx1 = np.random.randint(100)\n",
    "        idx2 = np.random.randint(100, 200)\n",
    "        idx3 = np.random.randint(200, 300)\n",
    "\n",
    "        m1 = m[idx1]\n",
    "        m2 = m[idx2]\n",
    "        m3 = m[idx3]\n",
    "\n",
    "        Vms1 = nest.GetStatus(m1)[0][\"events\"][\"V_m\"]\n",
    "        Vms2 = nest.GetStatus(m2)[0][\"events\"][\"V_m\"]\n",
    "        Vms3 = nest.GetStatus(m3)[0][\"events\"][\"V_m\"]\n",
    "\n",
    "        for i, offset in enumerate(offsets):\n",
    "            diff12 = Vms1[start_idx : end_idx] - Vms2[start_idx + offset: end_idx + offset]\n",
    "            diff13 = Vms1[start_idx : end_idx] - Vms3[start_idx + offset: end_idx + offset]\n",
    "            diff23 = Vms2[start_idx : end_idx] - Vms3[start_idx + offset: end_idx + offset]\n",
    "            hist12[sample, i] = len(diff12[np.abs(diff12) < threshold])\n",
    "            hist13[sample, i] = len(diff13[np.abs(diff13) < threshold])\n",
    "            hist23[sample, i] = len(diff23[np.abs(diff23) < threshold])\n",
    "            \n",
    "    hist12_mean = np.mean(hist12, axis=0)\n",
    "    hist13_mean = np.mean(hist13, axis=0)\n",
    "    hist23_mean = np.mean(hist23, axis=0)\n",
    "        \n",
    "    pylab.figure()\n",
    "    pylab.title(\"alpha & beta\")\n",
    "    pylab.bar(offsets, hist12_mean)\n",
    "    pylab.show()\n",
    "    pylab.figure()\n",
    "    pylab.title(\"alpha & gamma\")\n",
    "    pylab.bar(offsets, hist13_mean)\n",
    "    pylab.show()\n",
    "    pylab.figure()\n",
    "    pylab.title(\"beta & gamma\")\n",
    "    pylab.bar(offsets, hist23_mean)\n",
    "    pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def firing_hists():\n",
    "\n",
    "    ts1 = []      \n",
    "    ts2 = []      \n",
    "    ts3 = []    \n",
    "    \n",
    "    for i in range(100):\n",
    "        ts1.append(nest.GetStatus(s[i], keys=\"events\")[0][\"times\"])\n",
    "        ts2.append(nest.GetStatus(s[i+100], keys=\"events\")[0][\"times\"])\n",
    "        ts3.append(nest.GetStatus(s[i+200], keys=\"events\")[0][\"times\"])\n",
    "        \n",
    "    ts1 = np.hstack(ts1)\n",
    "    ts2 = np.hstack(ts2)\n",
    "    ts3 = np.hstack(ts3)\n",
    "    \n",
    "    bin_size = 1.\n",
    "    bins = np.arange(0, 500, bin_size)\n",
    "    \n",
    "    hist1, _ = np.histogram(ts1, bins=bins)\n",
    "    hist2, _ = np.histogram(ts2, bins=bins)\n",
    "    hist3, _ = np.histogram(ts3, bins=bins)\n",
    "    \n",
    "    bin_means = (bins - bin_size / 2)[1:]\n",
    "    \n",
    "    pylab.figure()\n",
    "    pylab.plot(bin_means, hist1)\n",
    "    pylab.plot(bin_means, hist2)\n",
    "    pylab.plot(bin_means, hist3)\n",
    "    pylab.legend([\"alhpa\", \"beta\", \"gamma\"])\n",
    "    pylab.xlabel(\"t\")\n",
    "    pylab.ylabel(\"Number of spikes\")\n",
    "    pylab.title(\"PTSH\")\n",
    "    pylab.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sns_plots():\n",
    "\n",
    "    pal = sns.cubehelix_palette(3, rot=-.5, dark=.3)\n",
    "    \n",
    "    idx1 = np.random.randint(100)\n",
    "    idx2 = np.random.randint(100, 200)\n",
    "    idx3 = np.random.randint(200, 300)\n",
    "\n",
    "    m1 = m[idx1]\n",
    "    m2 = m[idx2]\n",
    "    m3 = m[idx3]\n",
    "\n",
    "    Vms1 = nest.GetStatus(m1)[0][\"events\"][\"V_m\"]\n",
    "    Vms2 = nest.GetStatus(m2)[0][\"events\"][\"V_m\"]\n",
    "    Vms3 = nest.GetStatus(m3)[0][\"events\"][\"V_m\"]\n",
    "\n",
    "    diff12 = Vms1 - Vms2\n",
    "    diff13 = Vms1 - Vms3\n",
    "    diff23 = Vms2 - Vms3\n",
    "    \n",
    "    data = [diff12, diff13, diff23]\n",
    "    sns.violinplot(data=data, palette=pal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firing_hists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot before interpopulational connection\n",
    "raster_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coinc_hists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vm1 = np.reshape([nest.GetStatus(mult)[0][\"events\"][\"V_m\"] for mult in m], (300,1999))\n",
    "\n",
    "with open(\"vm1.csv\",\"w+\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',')\n",
    "    csvWriter.writerows(vm1)\n",
    "\n",
    "with open(\"sd1.csv\",\"w+\") as my_csv:    \n",
    "    csvWriter = csv.writer(my_csv,delimiter=',')\n",
    "    for spiked in s:\n",
    "        csvWriter.writerow(nest.GetStatus(spiked)[0][\"events\"][\"times\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
